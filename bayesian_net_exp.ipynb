{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libaray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Learning or Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "# Create Digraph object\n",
    "dot = Digraph()\n",
    "\n",
    "# Nodes\n",
    "dot.node('Smoker')\n",
    "dot.node('Gender')\n",
    "dot.node('Age')\n",
    "dot.node('Mutation')\n",
    "dot.node('Family')\n",
    "dot.node('Cancer')\n",
    "dot.node('Treatment')\n",
    "dot.node('Stage')\n",
    "dot.node('Relapse')\n",
    "\n",
    "# Edges\n",
    "lung_cancer_edges = [('Smoker', 'Mutation'), \n",
    "('Age', 'Smoker'), ('Age', 'Mutation'), ('Age', 'Relapse'),\n",
    "('Gender', 'Smoker'), ('Gender', 'Mutation'),\n",
    "('Mutation', 'Treatment'),\n",
    "('Treatment', 'Relapse'),\n",
    "('Family', 'Mutation'), ('Family', 'Relapse'),\n",
    "('Stage', 'Treatment'), ('Stage', 'Relapse')]\n",
    "\n",
    "for head, tail in lung_cancer_edges:\n",
    "    dot.edge(head, tail)\n",
    "\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Gender', 'Smoker', 'Stage', 'Family', 'Cancer', 'Mutation',\n",
      "       'FamilyTypeNum', 'Relapse'],\n",
      "      dtype='object')\n",
      "['Age', 'Gender', 'Smoker', 'Stage', 'Family', 'Cancer', 'Mutation', 'FamilyTypeNum', 'Relapse']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A', 'S'),\n",
       " ('A', 'S1'),\n",
       " ('A', 'C'),\n",
       " ('G', 'A'),\n",
       " ('G', 'S'),\n",
       " ('G', 'C'),\n",
       " ('S1', 'F'),\n",
       " ('S1', 'FN'),\n",
       " ('F', 'S'),\n",
       " ('C', 'FN'),\n",
       " ('M', 'A'),\n",
       " ('M', 'S'),\n",
       " ('M', 'C'),\n",
       " ('M', 'R'),\n",
       " ('FN', 'F'),\n",
       " ('R', 'G'),\n",
       " ('R', 'S1'),\n",
       " ('R', 'F'),\n",
       " ('R', 'C')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '''0   0   1   1   0   1   0   0   0\n",
    "   1   0   1   0   0   1   0   0   0\n",
    "   0   0   0   0   0   0   0   0   0\n",
    "   0   0   0   0   1   0   0   1   0\n",
    "   0   0   1   0   0   0   0   0   0\n",
    "   0   0   0   0   0   0   0   1   0\n",
    "   1   0   1   0   0   1   0   0   1\n",
    "   0   0   0   0   1   0   0   0   0\n",
    "   0   1   0   1   1   1   0   0   0'''\n",
    "\n",
    "from bn_library import mcmc_edges\n",
    "mcmc_edges(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Import dataset..\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'bn_library' has no attribute 'structure_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000005?line=31'>32</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbnlearn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000005?line=32'>33</a>\u001b[0m df \u001b[39m=\u001b[39m bnlearn\u001b[39m.\u001b[39mimport_example()[:\u001b[39m500\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000005?line=34'>35</a>\u001b[0m DAG \u001b[39m=\u001b[39m bn\u001b[39m.\u001b[39;49mstructure_learning\u001b[39m.\u001b[39mfit(df, methodtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhc\u001b[39m\u001b[39m'\u001b[39m, root_node\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m, bw_list_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnodes\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000005?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(DAG)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000005?line=38'>39</a>\u001b[0m \u001b[39m# Plot\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bn_library' has no attribute 'structure_learning'"
     ]
    }
   ],
   "source": [
    "from sympy import im\n",
    "import bn_library as bn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import mcmc_structure_learn as mcmc\n",
    "\n",
    "structure_methods = {\"ex\": bn.exhaustive_search, 'hc': bn.hill_climate, 'tan': bn.TAN, 'k2': bn.K2, 'pc': bn.constraint_based, 'mmhc': bn.mmhc}\n",
    "def structure_learn(data, Y):\n",
    "    strus = {}\n",
    "    for key, method in structure_methods.items():\n",
    "        if 'ex' == key:\n",
    "            continue\n",
    "        if 'tan' == key:\n",
    "            stru = structure_methods[key](data, Y, 'bic')\n",
    "        elif 'pc' == key:\n",
    "            stru = structure_methods[key](data)\n",
    "        else:\n",
    "            stru = structure_methods[key](data, 'bic')\n",
    "        strus[key] = stru\n",
    "    return strus\n",
    "    \n",
    "# Data load\n",
    "# df = pd.read_csv(\"query4_binary_Y_Feature.csv\")\n",
    "\n",
    "# from pgmpy.estimators import HillClimbSearch\n",
    "# from pgmpy.estimators import K2Score, BicScore\n",
    "# hc = HillClimbSearch(df)\n",
    "# best_model = hc.estimate()\n",
    "# print(best_model.edges())\n",
    "\n",
    "\n",
    "import bnlearn\n",
    "df = bnlearn.import_example()[:500]\n",
    "\n",
    "\n",
    "\n",
    "DAG = bn.structure_learning.fit(df, methodtype='hc', root_node='Survived', bw_list_method='nodes', verbose=3)\n",
    "\n",
    "print(DAG)\n",
    "\n",
    "# Plot\n",
    "G = bn.plot(DAG)\n",
    "\n",
    "# Parameter learning\n",
    "model = bn.parameter_learning.fit(DAG, df, verbose=3);\n",
    "\n",
    "# # Bayesian Network training\n",
    "# Y = 'Mutation'\n",
    "# struts = structure_learn(df, Y)\n",
    "# models = {key: bn.MLE(stru, df) for key, stru in struts.items()}\n",
    "\n",
    "# # evaluation\n",
    "# results = {\"model\": [], \"log_likelihood\": [], \"accuracy\": [], 'auc': []}\n",
    "# for key, model in models.items():\n",
    "#     print(key)\n",
    "#     results['model'].append(key)\n",
    "#     results['log_likelihood'].append(bn.log_likelihood(model, df))\n",
    "#     results['accuracy'].append(bn.accuracy(model, Y, df))\n",
    "#     results['auc'].append(bn.auc(model, Y, df))\n",
    "# pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Import dataset..\n",
      "[bnlearn] >Computing best DAG using [hc]\n",
      "[bnlearn] >Set scoring type at [bic]\n",
      "[('Cloudy', 'Rain'), ('Sprinkler', 'Wet_Grass'), ('Sprinkler', 'Cloudy'), ('Rain', 'Wet_Grass')]\n",
      "[bnlearn] >Parameter learning> Computing parameters using [bayes]\n",
      "[bnlearn] >Conversion of adjmat to BayesianNetwork.\n"
     ]
    },
    {
     "ename": "NetworkXError",
     "evalue": "Input is not a valid edge list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/networkx/convert.py:172\u001b[0m, in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m from_edgelist(data, create_using\u001b[39m=\u001b[39;49mcreate_using)\n\u001b[1;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/networkx/convert.py:490\u001b[0m, in \u001b[0;36mfrom_edgelist\u001b[0;34m(edgelist, create_using)\u001b[0m\n\u001b[1;32m    489\u001b[0m G \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mempty_graph(\u001b[39m0\u001b[39m, create_using)\n\u001b[0;32m--> 490\u001b[0m G\u001b[39m.\u001b[39;49madd_edges_from(edgelist)\n\u001b[1;32m    491\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pgmpy/base/DAG.py:285\u001b[0m, in \u001b[0;36mDAG.add_edges_from\u001b[0;34m(self, ebunch, weights)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m ebunch:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_edge(edge[\u001b[39m0\u001b[39;49m], edge[\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pgmpy/models/BayesianNetwork.py:124\u001b[0m, in \u001b[0;36mBayesianNetwork.add_edge\u001b[0;34m(self, u, v, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m u \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnodes() \u001b[39mand\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnodes() \u001b[39mand\u001b[39;00m nx\u001b[39m.\u001b[39mhas_path(\u001b[39mself\u001b[39m, v, u):\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    125\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLoops are not allowed. Adding the edge from (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m->\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) forms a loop.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39m%\u001b[39m (u, v)\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Loops are not allowed. Adding the edge from (Wet_Grass->Cloudy) forms a loop.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=21'>22</a>\u001b[0m DAG \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmodel_edges\u001b[39m\u001b[39m\"\u001b[39m: skeleton, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=22'>23</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39madjmat\u001b[39m\u001b[39m'\u001b[39m: edge2adjmat(skeleton),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=23'>24</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=24'>25</a>\u001b[0m \u001b[39m# 'model': BayesianModel(skeleton)}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=25'>26</a>\u001b[0m \u001b[39m# print(edge2adjmat(skeleton))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=26'>27</a>\u001b[0m \u001b[39m# print(df.columns)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=29'>30</a>\u001b[0m \u001b[39m# G = bn.plot(DAG)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=30'>31</a>\u001b[0m \u001b[39m# Parameter learning\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jason/Documents/Coding/BayeNet_Lung/bayesian_net_exp.ipynb#ch0000007?line=31'>32</a>\u001b[0m model \u001b[39m=\u001b[39m bn\u001b[39m.\u001b[39;49mparameter_learning\u001b[39m.\u001b[39;49mfit(DAG, df, verbose\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/bnlearn/parameter_learning.py:119\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, df, methodtype, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m# Convert to BayesianNetwork\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mBayesianNetwork\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(model)):\n\u001b[0;32m--> 119\u001b[0m     model \u001b[39m=\u001b[39m bnlearn\u001b[39m.\u001b[39;49mto_bayesianmodel(adjmat, verbose\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    121\u001b[0m \u001b[39m# pe = ParameterEstimator(model, df)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m# print(\"\\n\", pe.state_counts('Cloudy'))\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# print(\"\\n\", pe.state_counts('Sprinkler'))\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[39m# Learning CPDs using Maximum Likelihood Estimators\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mml\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximumlikelihood\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# model = MaximumLikelihoodEstimator(model, df)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[39m# for node in model.state_names:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39m#     print(model.estimate_cpd(node))\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/bnlearn/bnlearn.py:70\u001b[0m, in \u001b[0;36mto_bayesianmodel\u001b[0;34m(model, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m vec \u001b[39m=\u001b[39m adjmat2vec(adjmat)[[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     69\u001b[0m \u001b[39m# Make BayesianNetwork\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m bayesianmodel \u001b[39m=\u001b[39m BayesianNetwork(vec)\n\u001b[1;32m     71\u001b[0m \u001b[39m# Return\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m bayesianmodel\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pgmpy/models/BayesianNetwork.py:98\u001b[0m, in \u001b[0;36mBayesianNetwork.__init__\u001b[0;34m(self, ebunch, latents)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ebunch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, latents\u001b[39m=\u001b[39m\u001b[39mset\u001b[39m()):\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    Initializes a Bayesian Model.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m    A models stores nodes and edges with conditional probability\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m    3\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[39msuper\u001b[39;49m(BayesianNetwork, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(ebunch\u001b[39m=\u001b[39;49mebunch, latents\u001b[39m=\u001b[39;49mlatents)\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcpds \u001b[39m=\u001b[39m []\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcardinalities \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/pgmpy/base/DAG.py:74\u001b[0m, in \u001b[0;36mDAG.__init__\u001b[0;34m(self, ebunch, latents)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ebunch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, latents\u001b[39m=\u001b[39m\u001b[39mset\u001b[39m()):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m(DAG, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(ebunch)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatents \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(latents)\n\u001b[1;32m     76\u001b[0m     cycles \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/networkx/classes/digraph.py:327\u001b[0m, in \u001b[0;36mDiGraph.__init__\u001b[0;34m(self, incoming_graph_data, **attr)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39m# attempt to load graph with data\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m incoming_graph_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     convert\u001b[39m.\u001b[39;49mto_networkx_graph(incoming_graph_data, create_using\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    328\u001b[0m \u001b[39m# load graph attributes (must be after convert)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mupdate(attr)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch38/lib/python3.8/site-packages/networkx/convert.py:174\u001b[0m, in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[39mreturn\u001b[39;00m from_edgelist(data, create_using\u001b[39m=\u001b[39mcreate_using)\n\u001b[1;32m    173\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 174\u001b[0m         \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mInput is not a valid edge list\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mInput is not a known data type for conversion.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNetworkXError\u001b[0m: Input is not a valid edge list"
     ]
    }
   ],
   "source": [
    "import bnlearn as bn\n",
    "df = bn.import_example()[:500]\n",
    "import pandas as pd\n",
    "\n",
    "DAG = bn.structure_learning.fit(df, methodtype='hc', root_node='Survived', bw_list_method='nodes', verbose=3)\n",
    "\n",
    "# print(DAG)\n",
    "# print(type(DAG['model']))\n",
    "# print(DAG['model'])\n",
    "print(DAG['model_edges'])\n",
    "\n",
    "\n",
    "def edge2adjmat(edges):\n",
    "    nodes = list(set([item for t in edges for item in t]))\n",
    "    mat = [[False] * len(nodes)] * len(nodes)\n",
    "    for e in edges:\n",
    "        mat[nodes.index(e[0])][nodes.index(e[1])] = True\n",
    "    return pd.DataFrame(mat, index=nodes, columns=nodes)\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "skeleton = [('Cloudy', 'Rain'), ('Sprinkler', 'Wet_Grass'), ('Sprinkler', 'Cloudy'), ('Rain', 'Wet_Grass')]\n",
    "DAG = {\"model_edges\": skeleton, \n",
    "'adjmat': edge2adjmat(skeleton),\n",
    "'model': None}\n",
    "# 'model': BayesianModel(skeleton)}\n",
    "# print(edge2adjmat(skeleton))\n",
    "# print(df.columns)\n",
    "\n",
    "# Plot\n",
    "# G = bn.plot(DAG)\n",
    "# Parameter learning\n",
    "model = bn.parameter_learning.fit(DAG, df, verbose=3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_node_feature_names(edges, data):\n",
    "    features = set(data.head().columns)\n",
    "    node_names = set([node for node_pair in edges for node in node_pair])\n",
    "    assert(not features.difference(node_names))\n",
    "\n",
    "def paras_learn_by_bayes(edges, data):\n",
    "    check_node_feature_names(edges, data)\n",
    "    # Make the actual Bayesian DAG\n",
    "    DAG = bn.make_DAG(edges, verbose=0, methodtype='bayes')\n",
    "    model = bn.parameter_learning.fit(DAG, data, verbose=3, methodtype='bayes')\n",
    "    bn.print_CPD(model)\n",
    "    return model\n",
    "\n",
    "def paras_learn_by_ML(edges, data):\n",
    "    check_node_feature_names(edges, data)\n",
    "    DAG = bn.make_DAG(edges, verbose=0, methodtype='bayes')\n",
    "    # print(DAG)\n",
    "    # print(set(data.head().columns))\n",
    "    model = bn.parameter_learning.fit(DAG, data, methodtype='ml')\n",
    "    bn.print_CPD(model)\n",
    "    return model\n",
    "\n",
    "edges = [('Cloudy', 'Sprinkler'),\n",
    "         ('Cloudy', 'Rain'),\n",
    "         ('Sprinkler', 'Wet_Grass'),\n",
    "         ('Rain', 'Wet_Grass')]\n",
    "\n",
    "# paras_learn_by_bayes(edges, df)\n",
    "# paras_learn_by_ML(edges, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_learn_by_data(data, structure_setting, para_settting):\n",
    "    if structure_setting == 'cs':\n",
    "        model = bn.structure_learning.fit(data, methodtype='cs')\n",
    "    else:\n",
    "        model = bn.structure_learning.fit(data, methodtype=structure_setting, scoretype='bic')\n",
    "    # prune insignificant edges\n",
    "    model = bn.independence_test(model, data, alpha=0.05, prune=True)\n",
    "    model_bn = bn.parameter_learning.fit(model, df, methodtype=para_settting)  # maximum likelihood estimator\n",
    "    return model_bn\n",
    "\n",
    "def bn_defined():\n",
    "    from pgmpy.factors.discrete import TabularCPD\n",
    "    edges = structure_defined()\n",
    "    DAG = bn.make_DAG(edges)\n",
    "    # Cloudy\n",
    "    cpt_cloudy = TabularCPD(variable='Cloudy', variable_card=2, values=[[0.3], [0.7]])\n",
    "    print(cpt_cloudy)\n",
    "\n",
    "    # Sprinkler\n",
    "    cpt_sprinkler = TabularCPD(variable='Sprinkler', variable_card=2,\n",
    "                            values=[[0.4, 0.9], [0.6, 0.1]],\n",
    "                            evidence=['Cloudy'], evidence_card=[2])\n",
    "    print(cpt_sprinkler)\n",
    "\n",
    "    # Rain\n",
    "    cpt_rain = TabularCPD(variable='Rain', variable_card=2,\n",
    "                        values=[[0.8, 0.2], [0.2, 0.8]],\n",
    "                        evidence=['Cloudy'], evidence_card=[2])\n",
    "    print(cpt_rain)\n",
    "\n",
    "    # Wet Grass\n",
    "    cpt_wet_grass = TabularCPD(variable='Wet_Grass', variable_card=2,\n",
    "                            values=[[1, 0.1, 0.1, 0.01],\n",
    "                                    [0, 0.9, 0.9, 0.99]],\n",
    "                            evidence=['Sprinkler', 'Rain'],\n",
    "                            evidence_card=[2, 2])\n",
    "    DAG = bn.make_DAG(DAG, CPD=[cpt_cloudy, cpt_sprinkler, cpt_rain, cpt_wet_grass])\n",
    "    return DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "bn.save(model, filepath='bnlearn_model', overwrite=True)\n",
    "# Learn structure\n",
    "model = bn.structure_learning.fit(df, methodtype='tan', class_node='lung')# Load model\n",
    "model = bn.load(filepath='bnlearn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b\n",
      "a  1.000000  0.323835\n",
      "b  0.323835  1.000000\n",
      "{'a': 1, 'b': 2}\n",
      "{'a': 23, 'b': 34}\n",
      "{'a': 4, 'b': 54}\n",
      "{'a': 5, 'b': 6}\n",
      "[1, 23, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1,23,4,5], \"b\":[2,34,54,6]})\n",
    "\n",
    "df[\"a\"].values.tolist()\n",
    "print(df.corr())\n",
    "\n",
    "for k, row in df.iterrows():\n",
    "    print(row.to_dict())\n",
    "# df.drop('a', axis=1, inplace=True)\n",
    "print(df['a'].value_counts().keys().to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(grade:2 | intel:2, diff:2) at 0x7fc7516fad60>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "student = BayesianNetwork([('diff', 'grade'), ('intel', 'grade')])\n",
    "cpd = TabularCPD('grade', 2, [[0.1, 0.9, 0.2, 0.7],\n",
    "                                      [0.9, 0.1, 0.8, 0.3]],\n",
    "                          ['intel', 'diff'], [2, 2])\n",
    "student.add_cpds(cpd)\n",
    "student.get_cpds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "y = np.array(['a', 'b', 'a', 'b'])\n",
    "y_dict = {e: i for i, e in enumerate(set(y))}\n",
    "scores = np.array(['a', 'a', 'a', 'b'])\n",
    "\n",
    "y = [y_dict[e] for e in y]\n",
    "scores = [y_dict[e] for e in scores]\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, scores)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Import <sprinkler>\n",
      "[bnlearn] >Checking CPDs..\n",
      "[bnlearn] >Check for DAG structure. Correct: True\n",
      "[bnlearn] >Forward sampling for 500 samples..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532b0ed66d5a4d309c5dc4d1a11905f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load example DAG with CPD\n",
    "model = bn.import_DAG('sprinkler', CPD=True)\n",
    "\n",
    "# Take 1000 samples from the CPD distribution\n",
    "df = bn.sampling(model, n=500)\n",
    "\n",
    "df.to_csv('sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Import <sprinkler>\n",
      "[bnlearn] >Checking CPDs..\n",
      "[bnlearn] >Check for DAG structure. Correct: True\n",
      "[bnlearn] >Forward sampling for 1000 samples..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d991d0737fb4f6d827ad2bc35967f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    549\n",
      "0    451\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "Name: Cloudy, dtype: int64\n",
      "Index(['Cloudy', 'Sprinkler', 'Rain', 'Wet_Grass'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2005.8161942341667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bnlearn as bn\n",
    "model = bn.import_DAG('sprinkler', CPD=True)\n",
    "\n",
    "# Take 1000 samples from the CPD distribution\n",
    "df = bn.sampling(model, n=1000)\n",
    "df.loc[len(df)] = [2, 1, 0, 1]\n",
    "df.loc[len(df)] = [3, 1, 0, 1]\n",
    "df.loc[len(df)] = [4, 3, 2, 3]\n",
    "\n",
    "\n",
    "print(df.columns)\n",
    "skeleton = [('Cloudy', 'Rain'), ('Sprinkler', 'Wet_Grass'), ('Rain', 'Wet_Grass')]\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.metrics import log_likelihood_score\n",
    "model = BayesianModel(skeleton)\n",
    "model.fit(df, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "log_likelihood_score(model, df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rain', 'Wet_Grass'),\n",
       " ('Cloudy', 'Rain'),\n",
       " ('Sprinkler', 'Wet_Grass'),\n",
       " ('Cloudy', 'Sprinkler')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyAgrum as gum\n",
    "import pandas as pd\n",
    "import random\n",
    "# reference https://agrum.gitlab.io/articles/agrumpyagrum-0229-and-dataframe.html\n",
    "\n",
    "train_data = pd.read_csv('sample.csv')\n",
    "\n",
    "s_learner = gum.BNLearner(train_data)  # creates a learner by passing the dataframe\n",
    "# s_learner.useGreedyHillClimbing()     # sets a local-search algorithm for the structural learning\n",
    "s_learner.useK2(random.shuffle([i for i in range(len(train_data.columns))]))\n",
    "s_learner.useScoreBIC()               # sets BIC score as the metric\n",
    "structure = s_learner.learnBN()       # learning the structure\n",
    "\n",
    "id2name = {structure.idFromName(node_n): node_n for node_n in structure.names()}\n",
    "[(id2name[ele[0]], id2name[ele[1]]) for ele in structure.arcs()]\n",
    "\n",
    "# print(structure.arcs())\n",
    "# print(structure.nodes())\n",
    "# # print(train_data.columns)\n",
    "# print(structure.names())\n",
    "# # print(structure.cpt('Rain'))\n",
    "# print(structure.idFromName('Rain'))\n",
    "# print(structure.toDot())\n",
    "# structure.dag()\n",
    "\n",
    "# bn_learned = gum.BayesNet(structure)                   # initializing the bn with the learned structure\n",
    "# p_learner = gum.BNLearner(train_data, structure)  # crates a learner to learn parameters\n",
    "# p_learner.useEM(1e-10)                                 # sets EM to learn parameters\n",
    "# p_learner.fitParameters(bn_learned)                            # learning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Gender', 'Smoker', 'Stage', 'Family', 'Cancer', 'Mutation',\n",
      "       'FamilyTypeNum', 'Relapse'],\n",
      "      dtype='object')\n",
      "['Age', 'Gender', 'Smoker', 'Stage', 'Family', 'Cancer', 'Mutation', 'FamilyTypeNum', 'Relapse']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A', 'G'),\n",
       " ('A', 'S'),\n",
       " ('A', 'S1'),\n",
       " ('A', 'C'),\n",
       " ('A', 'R'),\n",
       " ('G', 'S'),\n",
       " ('G', 'F'),\n",
       " ('G', 'C'),\n",
       " ('S', 'S1'),\n",
       " ('S', 'FN'),\n",
       " ('F', 'S'),\n",
       " ('F', 'C'),\n",
       " ('F', 'FN'),\n",
       " ('C', 'FN'),\n",
       " ('M', 'A'),\n",
       " ('M', 'S'),\n",
       " ('M', 'S1'),\n",
       " ('M', 'F'),\n",
       " ('M', 'C'),\n",
       " ('M', 'R'),\n",
       " ('R', 'G'),\n",
       " ('R', 'S'),\n",
       " ('R', 'S1'),\n",
       " ('R', 'F'),\n",
       " ('R', 'C')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '''0   1   0   1   0   1   0   0   1\n",
    "0   0   1   1   1   1   0   0   0\n",
    "0   0   0   0   1   0   0   1   0\n",
    "0   0   1   0   0   0   0   0   0\n",
    "0   0   0   0   0   1   0   1   0\n",
    "0   0   0   0   0   0   0   1   0\n",
    "1   1   1   0   1   1   0   0   1\n",
    "0   0   0   0   0   0   0   0   0\n",
    "0   1   1   1   1   1   0   0   0'''\n",
    "\n",
    "s2 = '''0   1   1   1   0   1   0   0   1\n",
    "   0   0   1   0   1   1   0   0   0\n",
    "   0   0   0   1   0   0   0   1   0\n",
    "   0   0   0   0   0   0   0   0   0\n",
    "   0   0   1   0   0   1   0   1   0\n",
    "   0   0   0   0   0   0   0   1   0\n",
    "   1   0   1   1   1   1   0   0   1\n",
    "   0   0   0   0   0   0   0   0   0\n",
    "   0   1   1   1   1   1   0   0   0'''\n",
    "def mcmc_edges(a):\n",
    "    '''a is a str representing the adjacent matrix'''\n",
    "    brief = {'M':'Mutation', 'FN':'FamilyTypeNum', 'R':'Relapse', 'A': 'Age', 'C':'Cancer', \n",
    "'F':'Family', 'S1' :'Stage', 'G': 'Gender', 'S':'Smoker'}\n",
    "    long_s = {v:k for k, v in brief.items()}\n",
    "    b = a.split()\n",
    "    N = 9\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    b = np.array([int(b[i*N+j]) for i in range(N) for j in range(N)]).reshape((N,N))\n",
    "\n",
    "    df = pd.read_csv('query4R.csv')\n",
    "    print(df.columns)\n",
    "\n",
    "    cols = df.columns.to_list()\n",
    "    print(cols)\n",
    "\n",
    "    edges = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if b[i][j] == 1:\n",
    "                edges.append((cols[i], cols[j]))\n",
    "    edges = [(long_s[ele[0]],long_s[ele[1]]) for ele in edges]\n",
    "    return edges\n",
    "mcmc_edges(s2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('causal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a12683aaeac14c2deaa80343f1f02d5d856b61624c85c95b391f69b4cda60a8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
